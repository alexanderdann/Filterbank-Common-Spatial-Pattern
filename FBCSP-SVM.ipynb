{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import logging\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import mutual_info_classif as MIBIF\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from scipy.signal import cheby1, butter, sosfilt\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from mne.decoding import CSP\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "from utilities import get_npz_data, get_project_data, get_bci_iii_data, get_prev_project_data\n",
    "\n",
    "logger = logging.getLogger('FBCSP-SVM')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.StreamHandler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LOG_PATH = f'{os.getcwd()}/LOG/1dAX_LSTM'\n",
    "\n",
    "HYBRID_DATA_PATH = f'{os.getcwd()}/Data/Hybrid'\n",
    "BCI_IV_2a_DATA_PATH = f'{os.getcwd()}/Data/BCI'\n",
    "BCI_III_IVa_DATA_PATH = f'{os.getcwd()}/Data/BCI III IVa'\n",
    "\n",
    "EEG, TARGET = get_project_data(HYBRID_DATA_PATH, [2.0, 3.0], sec=3, offset=1)\n",
    "\n",
    "if not os.path.exists(LOG_PATH):\n",
    "    os.makedirs(LOG_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Data Preprocessing\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _preprocessing(data):\n",
    "    logger.info(f'Preprocessing data')\n",
    "    return StandardScaler().fit_transform(X=data)\n",
    "\n",
    "def ivstack(data, shape):\n",
    "    unstack = np.empty(shape=shape)\n",
    "    for idx, _ in enumerate(unstack):\n",
    "        for idy, da in enumerate(data):\n",
    "            unstack[idx, idy] = da[idx*shape[-1]:(idx+1)*shape[-1]]\n",
    "    return unstack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing\n",
    "-----\n",
    "### We pass the data through a filter bank and calculate CSP features afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def filter_bank(data, bands=None):\n",
    "    if bands is None:\n",
    "        keys = [f'b{i}' for i in range(9)]\n",
    "        vals = [[i*4, (i+1)*4] for i in range(1, 10)]\n",
    "        bands = dict(zip(keys, vals))\n",
    "    else:\n",
    "        assert isinstance(bands, dict), logger.error('Bands for filter bank have wrong data type')\n",
    "\n",
    "    num_trials, num_samples, num_channels = data.shape\n",
    "    num_bands = len(bands)\n",
    "    filter_data = np.zeros(shape=(num_bands, num_trials, num_channels, num_samples))\n",
    "\n",
    "    for band_idx, (band, frequencies) in enumerate(tqdm(bands.items(), desc='Filter bank')):\n",
    "        for trial_idx, trial in enumerate(data):\n",
    "            for channel_idx, channel in enumerate(trial.T):\n",
    "                sos = butter(N=5, Wn=[i/128 for i in frequencies], output='sos', btype='bandpass')\n",
    "                filter_data[band_idx, trial_idx, channel_idx, :] = sosfilt(sos, channel)\n",
    "\n",
    "    return filter_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def common_spatial_pattern(data, target, num_components):\n",
    "    num_bands, num_trials, num_channels, num_samples = data.shape\n",
    "    reduced_dim = 4\n",
    "    csp_features = np.zeros(shape=(num_bands, num_trials, reduced_dim))\n",
    "    \n",
    "    if num_components == 4:\n",
    "        csp_models = [CSP(n_components=num_channels, transform_into='csp_space')\n",
    "                      for _ in range(num_bands)]\n",
    "    else:\n",
    "        csp_models = [CSP(n_components=num_channels, transform_into='csp_space', component_order='alternate')\n",
    "                      for _ in range(num_bands)]\n",
    "        \n",
    "    for band_idx in tqdm(range(num_bands), desc='CSP feature extraction'):\n",
    "        Z_p = csp_models[band_idx].fit(X=data[band_idx], y=target).transform(X=data[band_idx])[:, :reduced_dim]\n",
    "        for trial_idx in range(num_trials):\n",
    "            z = Z_p[trial_idx]\n",
    "            log_var = np.log(np.std(z, axis=1)**2 / np.sum(np.std(z, axis=1)**2))\n",
    "            csp_features[band_idx, trial_idx] = log_var\n",
    "            \n",
    "    return csp_features, csp_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Feature Selection\n",
    "------\n",
    "### Select num_features which maximise the mutual information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def feature_selection(data, target, num_features=4):\n",
    "    logger.info(f'Feature selection')\n",
    "    all_idx = list()\n",
    "    for band in data:\n",
    "        all_idx.append(np.sum(MIBIF(band, target)))\n",
    "\n",
    "    most_informative_idx = list()\n",
    "    for i in range(num_features):\n",
    "        idx = np.argmax(all_idx)\n",
    "        most_informative_idx.append(idx)\n",
    "        all_idx[idx] = -1\n",
    "\n",
    "    return np.concatenate(np.copy(data[most_informative_idx]), axis=1), most_informative_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suport Vector Machine\n",
    "-----------\n",
    "### Training a SVM with a linear kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(data, target):\n",
    "    logger.info(f'Training model')\n",
    "    model = SVC(kernel='linear', verbose=1, random_state=3333)\n",
    "    model.fit(data, target)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "----------\n",
    "### Combining all processing steps into a pipeline whih returns the needed parameters for further classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def pipeline(data, target, classes_idx):\n",
    "    num_components = len(classes_idx)\n",
    "    logger.info(f'Entering pipeline')\n",
    "    filtered_data = filter_bank(data)\n",
    "    csp_features, csp_models = common_spatial_pattern(filtered_data, target, num_components)\n",
    "    fsdata, idx_params = feature_selection(csp_features, target)\n",
    "    svm_model = train(fsdata, target)\n",
    "\n",
    "    return csp_models, idx_params, svm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def csp_fit(data, csp_models, reduced_dim=4):\n",
    "    logger.info(f'CSP transform')\n",
    "    num_bands, num_trials, num_channels, num_samples = data.shape\n",
    "    csp_features = np.zeros(shape=(num_bands, num_trials, reduced_dim))\n",
    "\n",
    "    for band_idx, model in enumerate(csp_models):\n",
    "        Z_p = model.transform(data[band_idx])[:,:reduced_dim]\n",
    "        for trial_idx in range(num_trials):\n",
    "            z = Z_p[trial_idx]\n",
    "            log_var = np.log(np.std(z, axis=1)**2 / np.sum(np.std(z, axis=1)**2))\n",
    "            csp_features[band_idx, trial_idx] = log_var\n",
    "\n",
    "    return csp_features\n",
    "\n",
    "def mi_fit(data, params):\n",
    "    logger.info(f'MI transform')\n",
    "    return np.concatenate(data[params], axis=1)\n",
    "\n",
    "def predict(data, true_labels, csp_models, idx_params, svm_model):\n",
    "    filtered_data = filter_bank(data)\n",
    "    csp_features = csp_fit(filtered_data, csp_models)\n",
    "    mi_features = mi_fit(csp_features, idx_params)\n",
    "    logger.info(f'Prediction')\n",
    "    pred_labels = svm_model.predict(mi_features)\n",
    "    \n",
    "    return accuracy_score(true_labels, pred_labels), confusion_matrix(true_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "k_cross_val = 5\n",
    "t_sec = 3\n",
    "session_idx = 0\n",
    "\n",
    "for comb_idx, comb in enumerate([[769, 770], [770, 772]]):\n",
    "    EEG, TARGET, _ = get_npz_data(path=BCI_IV_2a_DATA_PATH, user='A01E', labels=comb, sec=t_sec)\n",
    "    accuracies = list()\n",
    "    \n",
    "    path = f'LOG/CIDX-{comb_idx}'\n",
    "    with tf.summary.create_file_writer(path).as_default(): \n",
    "        for fold_idx, (train_idx, test_idx) in enumerate(StratifiedKFold(n_splits=k_cross_val).split(np.zeros(shape=TARGET.shape), TARGET)):\n",
    "            EEG_TRAIN, TARGET_TRAIN = EEG[train_idx], TARGET[train_idx]\n",
    "            EEG_TEST, TARGET_TEST = EEG[test_idx], TARGET[test_idx]\n",
    "\n",
    "            trained_csp, trained_fs, trained_svm = pipeline(EEG_TRAIN, TARGET_TRAIN, comb)\n",
    "            acc, conf_matrix = predict(EEG_TEST, TARGET_TEST, trained_csp, trained_fs, trained_svm)\n",
    "            accuracies.append(acc)\n",
    "        \n",
    "            tf.summary.scalar(f'FIDX-{fold_idx}', tf.reduce_mean(accuracies), step=session_idx)\n",
    "    \n",
    "    session_idx += 1\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
